{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bcaff20d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Import all the functions you need\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "from neuropy import core\n",
    "from neuropy.io import (optitrackio,\n",
    "                        dlcio,\n",
    "                        )\n",
    "from neuropy.io.neuroscopeio import NeuroscopeIO\n",
    "from neuropy.io.binarysignalio import BinarysignalIO \n",
    "from neuropy.io.miniscopeio import MiniscopeIO\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "63ff1999",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a class for a typical recording or set of recordings\n",
    "class ProcessData:\n",
    "    def __init__(self, basepath):\n",
    "        basepath = Path(basepath)\n",
    "        self.basepath = basepath\n",
    "        xml_files = sorted(basepath.glob(\"*.xml\"))\n",
    "        assert len(xml_files) == 1, \"Found more than one .xml file\"\n",
    "        \n",
    "        fp = xml_files[0].with_suffix(\"\")\n",
    "        self.filePrefix = fp\n",
    "        \n",
    "        self.recinfo = NeuroscopeIO(xml_files[0])\n",
    "        self.eeginfo = BinarysignalIO(self.recinfo.eeg_filename,\n",
    "                                     n_channels=self.recinfo.n_channels,\n",
    "                                     sampling_rate=self.recinfo.eeg_sampling_rate,\n",
    "                                     )\n",
    "        \n",
    "    def __repr__(self) -> str:\n",
    "        return f\"{self.__class__.__name__}({self.recinfo.source_file.name})\"\n",
    "    \n",
    "def Rat698recall():\n",
    "    basepath='/data/Working/Trace_FC/Recording_Rats/Rat698/2021_06_30_recall'\n",
    "    return ProcessData(basepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "278841d2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filename: /data/Working/Trace_FC/Recording_Rats/Rat698/2021_06_30_recall/continuous_combined.xml \n",
      "# channels: 35\n",
      "sampling rate: 30000\n",
      "lfp Srate (downsampled): 1250\n"
     ]
    }
   ],
   "source": [
    "sess = Rat698recall()\n",
    "print(sess.recinfo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "716b1ff2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7240022"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.eeginfo.n_frames"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25ac88dc",
   "metadata": {},
   "source": [
    "# Import miniscope data and timestamps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6398be8b",
   "metadata": {},
   "source": [
    "First, run the session through the minian pipeline and save your S, A, and C variables to numpy arrays in a \"minian\" folder somewhere in the session folder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91de7008",
   "metadata": {},
   "source": [
    "Second, designate any *corrupted files* by creating a \"corrupted_videos.csv\" file in the folder where your timeStamps.csv file lives. List the index to each corrupted file separated by commas. Even if you have concatenated all your videos from different recordings together in minian this file you should still put this in the file for each recording with a corrupted file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "563d3bb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eliminating timestamps from corrupted video6 in 13_00_45 folder.\n"
     ]
    }
   ],
   "source": [
    "# Now, load in all the video timestamps and minian data.\n",
    "sess.miniscope = MiniscopeIO(sess.basepath)\n",
    "sess.miniscope.load_all_timestamps()\n",
    "sess.miniscope.load_minian()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac1b3683",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27367, 4)\n",
      "(80, 27367)\n"
     ]
    }
   ],
   "source": [
    "# Check that # timestamps matches neural data\n",
    "print(sess.miniscope.times_all.shape)\n",
    "print(sess.miniscope.minian['S'].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "666ce7da",
   "metadata": {},
   "source": [
    "# Get timestamps for neural data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "56223013",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/data/Working/Trace_FC/Recording_Rats/Rat698/2021_06_30_recall')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.basepath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ba726d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NRK start on 10/6/2021\n",
    "# 1) have timestamps for everything now, interpolate everything to ephys times! Or maybe just use timestamps?  \n",
    "# 2) Would be good to pull in my .eeg file and see what types of things I can analyze from it.  Also figure out\n",
    "# a way to import the mua from my 3-wire electrode.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be57f4ea",
   "metadata": {},
   "source": [
    "# Get TTLs to OE for synchronization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ee45d379",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NRK note - check in code if timestamps between OE and optitrack match up well, otherwise chuck them and go by timestamps!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01bcdcda",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "969242c3",
   "metadata": {},
   "source": [
    "# Plan for alignment\n",
    "designate each recording session in `epochs`, then have an `align_by` flag that will either align by TTL or by timestamps or, in the case of oe and position, align by theta v speed.  Also, for some sessions I have an input from the miniscope to Intan that I can use.\n",
    "\n",
    "Since some epochs will have a TTL at the start but not later on after a disconnect, you will need to either a) fake a \"disconnect\" event and only use the TTL if there is an off-on transition after the disconnect, or b) just search for the closet TTL PRIOR to each timestamp to figure out how to align it.  Function would look identify a range of times and then flag them as either \"align_by_timestamps\" or \"align_by_TTL\" or \"align_by_theta\" (position to oe only) or \"MS_to_oe_TTL\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1610d634",
   "metadata": {},
   "source": [
    "# Options for alignment\n",
    "\n",
    "## 1) TTL - digital or analog?\n",
    "\n",
    "## 2) Timestamps - currently not accurate enough\n",
    "\n",
    "## 3) theta as a backup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98916e67",
   "metadata": {},
   "source": [
    "# Read in DLC pos data and sync with Optitrack timestamps"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:NeuroPy] *",
   "language": "python",
   "name": "conda-env-NeuroPy-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
