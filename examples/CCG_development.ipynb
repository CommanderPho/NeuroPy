{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CCG Development"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notebook to compare CCG times to run in python vs. CCGheart.c mex MATLAB file from buzcode repo and develop a faster CCG in python if the python version runs much slower"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, import data to compare (neuron 20 vs 45 for 'RoyMaze1' session from Hiro dataset)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import loadmat\n",
    "\n",
    "filepath = '/data/Working/Other Peoples Data/HiroData/wake_new/wake-spikes.mat'\n",
    "session = 'RoyMaze1'\n",
    "\n",
    "mat_in = loadmat(filepath, squeeze_me=True, struct_as_record=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Organize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "neurons = [19, 44]\n",
    "spikes_use = [mat_in['spikes'].RoyMaze1[neuron] for neuron in neurons]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(517090,)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spikes_use[0].time.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import CCG from matlab and organize data nicely"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ccg\n",
    "import numpy as np\n",
    "\n",
    "time_to_sec = 1/(1000*1000)  # Hiro data times are in microseconds\n",
    "spikes_unsorted = np.concatenate([a.time for a in spikes_use])*time_to_sec  # assemble spikes\n",
    "clu_id = np.concatenate([[idc] * len(a.time) for idc, a in enumerate(spikes_use)])  # assemble cluster ids\n",
    "sort_ind = np.argsort(spikes_unsorted)\n",
    "spikes = spikes_unsorted[sort_ind]\n",
    "clu_id = clu_id[sort_ind]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now run CCG!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size, bin_size = 0.007, 1/30000\n",
    "ccgs = ccg.correlograms(spikes, clu_id, window_size=window_size, bin_size=bin_size, sample_rate=30000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now plot it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "# sns.barplot(y=ccgs[1,0,:])\n",
    "bins = np.linspace(-window_size/2, window_size/2, num=int(0.007/bin_size + 1))\n",
    "sns.barplot(x=bins, y=ccgs[1,0,:])\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, that looks like it works (fix color issues later).  Now time the ccg run!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "129 ms ± 497 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit ccg.correlograms(spikes, clu_id, window_size=window_size, bin_size=bin_size, sample_rate=30000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a bit slower than the CCGheart function in MATLAB, which appears to run at aroun 80ms per CCG. So I need to do some Cythoning below to touch things up!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, start by simply copying over the CCG function and compiling in Cython here..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext Cython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cython\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# Cross-correlograms\n",
    "# ------------------------------------------------------------------------------\n",
    "_ACCEPTED_ARRAY_DTYPES = (\n",
    "    np.float,\n",
    "    np.float32,\n",
    "    np.float64,\n",
    "    np.int,\n",
    "    np.int8,\n",
    "    np.int16,\n",
    "    np.uint8,\n",
    "    np.uint16,\n",
    "    np.int32,\n",
    "    np.int64,\n",
    "    np.uint32,\n",
    "    np.uint64,\n",
    "    np.bool,\n",
    ")\n",
    "\n",
    "\n",
    "def _as_array(arr, dtype=None):\n",
    "    \"\"\"Convert an object to a numerical NumPy array.\n",
    "    Avoid a copy if possible.\n",
    "    \"\"\"\n",
    "    if arr is None:\n",
    "        return None\n",
    "    if isinstance(arr, np.ndarray) and dtype is None:\n",
    "        return arr\n",
    "    if isinstance(arr, (int, float)):\n",
    "        arr = [arr]\n",
    "    out = np.asarray(arr)\n",
    "    if dtype is not None:\n",
    "        if out.dtype != dtype:\n",
    "            out = out.astype(dtype)\n",
    "    if out.dtype not in _ACCEPTED_ARRAY_DTYPES:\n",
    "        raise ValueError(\n",
    "            \"'arr' seems to have an invalid dtype: \" \"{0:s}\".format(str(out.dtype))\n",
    "        )\n",
    "    return out\n",
    "\n",
    "\n",
    "def _index_of(arr, lookup):\n",
    "    \"\"\"Replace scalars in an array by their indices in a lookup table.\n",
    "    Implicitely assume that:\n",
    "    * All elements of arr and lookup are non-negative integers.\n",
    "    * All elements or arr belong to lookup.\n",
    "    This is not checked for performance reasons.\n",
    "    \"\"\"\n",
    "    # Equivalent of np.digitize(arr, lookup) - 1, but much faster.\n",
    "    # TODO: assertions to disable in production for performance reasons.\n",
    "    # TODO: np.searchsorted(lookup, arr) is faster on small arrays with large\n",
    "    # values\n",
    "    lookup = np.asarray(lookup, dtype=np.int32)\n",
    "    m = (lookup.max() if len(lookup) else 0) + 1\n",
    "    tmp = np.zeros(m + 1, dtype=np.int)\n",
    "    # Ensure that -1 values are kept.\n",
    "    tmp[-1] = -1\n",
    "    if len(lookup):\n",
    "        tmp[lookup] = np.arange(len(lookup))\n",
    "    return tmp[arr]\n",
    "\n",
    "\n",
    "def _unique(x):\n",
    "    \"\"\"Faster version of np.unique().\n",
    "    This version is restricted to 1D arrays of non-negative integers.\n",
    "    It is only faster if len(x) >> len(unique(x)).\n",
    "    \"\"\"\n",
    "    if x is None or len(x) == 0:\n",
    "        return np.array([], dtype=np.int64)\n",
    "    # WARNING: only keep positive values.\n",
    "    # cluster=-1 means \"unclustered\".\n",
    "    x = _as_array(x)\n",
    "    x = x[x >= 0]\n",
    "    bc = np.bincount(x)\n",
    "    return np.nonzero(bc)[0]\n",
    "\n",
    "\n",
    "def _increment(arr, indices):\n",
    "    \"\"\"Increment some indices in a 1D vector of non-negative integers.\n",
    "    Repeated indices are taken into account.\"\"\"\n",
    "    arr = _as_array(arr)\n",
    "    indices = _as_array(indices)\n",
    "    bbins = np.bincount(indices)\n",
    "    arr[: len(bbins)] += bbins\n",
    "    return arr\n",
    "\n",
    "\n",
    "def _diff_shifted(arr, steps=1):\n",
    "    arr = _as_array(arr)\n",
    "    return arr[steps:] - arr[: len(arr) - steps]\n",
    "\n",
    "\n",
    "def _create_correlograms_array(n_clusters, winsize_bins):\n",
    "    return np.zeros((n_clusters, n_clusters, winsize_bins // 2 + 1), dtype=np.int32)\n",
    "\n",
    "\n",
    "def _symmetrize_correlograms(correlograms):\n",
    "    \"\"\"Return the symmetrized version of the CCG arrays.\"\"\"\n",
    "\n",
    "    n_clusters, _, n_bins = correlograms.shape\n",
    "    assert n_clusters == _\n",
    "\n",
    "    # We symmetrize c[i, j, 0].\n",
    "    # This is necessary because the algorithm in correlograms()\n",
    "    # is sensitive to the order of identical spikes.\n",
    "    correlograms[..., 0] = np.maximum(correlograms[..., 0], correlograms[..., 0].T)\n",
    "\n",
    "    sym = correlograms[..., 1:][..., ::-1]\n",
    "    sym = np.transpose(sym, (1, 0, 2))\n",
    "\n",
    "    return np.dstack((sym, correlograms))\n",
    "\n",
    "\n",
    "def firing_rate(spike_clusters, cluster_ids=None, bin_size=None, duration=None):\n",
    "    \"\"\"Compute the average number of spikes per cluster per bin.\"\"\"\n",
    "\n",
    "    # Take the cluster order into account.\n",
    "    if cluster_ids is None:\n",
    "        cluster_ids = _unique(spike_clusters)\n",
    "    else:\n",
    "        cluster_ids = _as_array(cluster_ids)\n",
    "\n",
    "    # Like spike_clusters, but with 0..n_clusters-1 indices.\n",
    "    spike_clusters_i = _index_of(spike_clusters, cluster_ids)\n",
    "\n",
    "    assert bin_size > 0\n",
    "    bc = np.bincount(spike_clusters_i)\n",
    "    # Handle the case where the last cluster(s) are empty.\n",
    "    if len(bc) < len(cluster_ids):\n",
    "        n = len(cluster_ids) - len(bc)\n",
    "        bc = np.concatenate((bc, np.zeros(n, dtype=bc.dtype)))\n",
    "    assert bc.shape == (len(cluster_ids),)\n",
    "    return bc * np.c_[bc] * (bin_size / (duration or 1.0))\n",
    "\n",
    "\n",
    "def correlograms_py(\n",
    "    spike_times,\n",
    "    spike_clusters,\n",
    "    cluster_ids=None,\n",
    "    sample_rate=1.0,\n",
    "    bin_size=None,\n",
    "    window_size=None,\n",
    "    symmetrize=True,\n",
    "):\n",
    "    \"\"\"Compute all pairwise cross-correlograms among the clusters appearing\n",
    "    in `spike_clusters`.\n",
    "    Parameters\n",
    "    ----------\n",
    "    spike_times : array-like\n",
    "        Spike times in seconds.\n",
    "    spike_clusters : array-like\n",
    "        Spike-cluster mapping.\n",
    "    cluster_ids : array-like\n",
    "        The list of *all* unique clusters, in any order. That order will be used\n",
    "        in the output array.\n",
    "    bin_size : float\n",
    "        Size of the bin, in seconds.\n",
    "    window_size : float\n",
    "        Size of the window, in seconds.\n",
    "    sample_rate : float\n",
    "        Sampling rate.\n",
    "    symmetrize : boolean (True)\n",
    "        Whether the output matrix should be symmetrized or not.\n",
    "    Returns\n",
    "    -------\n",
    "    correlograms : array\n",
    "        A `(n_clusters, n_clusters, winsize_samples)` array with all pairwise CCGs.\n",
    "    \"\"\"\n",
    "    assert sample_rate > 0.0\n",
    "    assert np.all(np.diff(spike_times) >= 0), \"The spike times must be \" \"increasing.\"\n",
    "\n",
    "    # Get the spike samples.\n",
    "    spike_times = np.asarray(spike_times, dtype=np.float64)\n",
    "    spike_samples = (spike_times * sample_rate).astype(np.int64)\n",
    "\n",
    "    spike_clusters = _as_array(spike_clusters)\n",
    "\n",
    "    assert spike_samples.ndim == 1\n",
    "    assert spike_samples.shape == spike_clusters.shape\n",
    "\n",
    "    # Find `binsize`.\n",
    "    bin_size = np.clip(bin_size, 1e-5, 1e5)  # in seconds\n",
    "    binsize = int(sample_rate * bin_size)  # in samples\n",
    "    assert binsize >= 1\n",
    "\n",
    "    # Find `winsize_bins`.\n",
    "    window_size = np.clip(window_size, 1e-5, 1e5)  # in seconds\n",
    "    winsize_bins = 2 * int(0.5 * window_size / bin_size) + 1\n",
    "\n",
    "    assert winsize_bins >= 1\n",
    "    assert winsize_bins % 2 == 1\n",
    "\n",
    "    # Take the cluster order into account.\n",
    "    if cluster_ids is None:\n",
    "        clusters = _unique(spike_clusters)\n",
    "    else:\n",
    "        clusters = _as_array(cluster_ids)\n",
    "    n_clusters = len(clusters)\n",
    "\n",
    "    # Like spike_clusters, but with 0..n_clusters-1 indices.\n",
    "    spike_clusters_i = _index_of(spike_clusters, clusters)\n",
    "\n",
    "    # Shift between the two copies of the spike trains.\n",
    "    shift = 1\n",
    "\n",
    "    # At a given shift, the mask precises which spikes have matching spikes\n",
    "    # within the correlogram time window.\n",
    "    mask = np.ones_like(spike_samples, dtype=np.bool)\n",
    "\n",
    "    correlograms = _create_correlograms_array(n_clusters, winsize_bins)\n",
    "\n",
    "    # The loop continues as long as there is at least one spike with\n",
    "    # a matching spike.\n",
    "    while mask[:-shift].any():\n",
    "        # Number of time samples between spike i and spike i+shift.\n",
    "        spike_diff = _diff_shifted(spike_samples, shift)\n",
    "\n",
    "        # Binarize the delays between spike i and spike i+shift.\n",
    "        spike_diff_b = spike_diff // binsize\n",
    "\n",
    "        # Spikes with no matching spikes are masked.\n",
    "        mask[:-shift][spike_diff_b > (winsize_bins // 2)] = False\n",
    "\n",
    "        # Cache the masked spike delays.\n",
    "        m = mask[:-shift].copy()\n",
    "        d = spike_diff_b[m]\n",
    "\n",
    "        # # Update the masks given the clusters to update.\n",
    "        # m0 = np.in1d(spike_clusters[:-shift], clusters)\n",
    "        # m = m & m0\n",
    "        # d = spike_diff_b[m]\n",
    "        d = spike_diff_b[m]\n",
    "\n",
    "        # Find the indices in the raveled correlograms array that need\n",
    "        # to be incremented, taking into account the spike clusters.\n",
    "        indices = np.ravel_multi_index(\n",
    "            (spike_clusters_i[:-shift][m], spike_clusters_i[+shift:][m], d),\n",
    "            correlograms.shape,\n",
    "        )\n",
    "\n",
    "        # Increment the matching spikes in the correlograms array.\n",
    "        _increment(correlograms.ravel(), indices)\n",
    "\n",
    "        shift += 1\n",
    "\n",
    "    if symmetrize:\n",
    "        return _symmetrize_correlograms(correlograms)\n",
    "    else:\n",
    "        return correlograms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow, that seemed to work. Now let's time it again!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "132 ms ± 176 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit correlograms_py(spikes, clu_id, window_size=window_size, bin_size=bin_size, sample_rate=30000) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, same result as before. Need to get fancier. Next try saving this as it's own file and complining outside this notebook. Maybe that will do better?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133 ms ± 372 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "import ccg_py  # this is the name of the file I compiled using `python setup.py build_ext --inplace`\n",
    "\n",
    "%timeit ccg_py.correlograms(spikes, clu_id, window_size=window_size, bin_size=bin_size, sample_rate=30000) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If not, move onto some of the first steps in the \"Cython for NumPy users\" tutorial: setting types and indexing with memoryviews."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start with setting types - do this on a function by function basis to debug and then combine at the end!  \n",
    "  \n",
    "IMPORTANT NOTE: Have to remove `_` before each function to test as that makes it a protected function that is inaccessible outside of the class. Remember to add those back in in the end!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the `_as_array` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cython\n",
    "# cython: infer_types=True\n",
    "cimport numpy as npc\n",
    "import numpy as np\n",
    "cimport cython\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# Cross-correlograms\n",
    "# ------------------------------------------------------------------------------\n",
    "_ACCEPTED_ARRAY_DTYPES = (\n",
    "    np.float,\n",
    "    np.float32,\n",
    "    np.float64,\n",
    "    np.int,\n",
    "    np.int8,\n",
    "    np.int16,\n",
    "    np.uint8,\n",
    "    np.uint16,\n",
    "    np.int32,\n",
    "    np.int64,\n",
    "    np.uint32,\n",
    "    np.uint64,\n",
    "    np.bool,\n",
    ")\n",
    "\n",
    "ctypedef fused my_type:\n",
    "    float\n",
    "    int\n",
    "    unsigned int\n",
    "    bint\n",
    "    list\n",
    "    npc.ndarray\n",
    "\n",
    "# NRK potential slowdonwn below with dtype unset.\n",
    "def as_array_cy(my_type arr, dtype=None):\n",
    "    \"\"\"Convert an object to a numerical NumPy array.\n",
    "    Avoid a copy if possible.\n",
    "    \"\"\"\n",
    "    cdef list arr_temp = []\n",
    "    if arr is None:\n",
    "        return None\n",
    "    if isinstance(arr, np.ndarray) and dtype is None:\n",
    "        return arr\n",
    "    if isinstance(arr, (int, float)):\n",
    "        arr_temp = [arr]\n",
    "    out = np.asarray(arr_temp)\n",
    "    if dtype is not None:\n",
    "        if out.dtype != dtype:\n",
    "            out = out.astype(dtype)\n",
    "    if out.dtype not in _ACCEPTED_ARRAY_DTYPES:\n",
    "        raise ValueError(\n",
    "            \"'arr' seems to have an invalid dtype: \" \"{0:s}\".format(str(out.dtype))\n",
    "        )\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "as_array_cy(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now compile pure python version and compare to make sure I'm not making things longer by accident"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# Cross-correlograms\n",
    "# ------------------------------------------------------------------------------\n",
    "_ACCEPTED_ARRAY_DTYPES = (\n",
    "    np.float,\n",
    "    np.float32,\n",
    "    np.float64,\n",
    "    np.int,\n",
    "    np.int8,\n",
    "    np.int16,\n",
    "    np.uint8,\n",
    "    np.uint16,\n",
    "    np.int32,\n",
    "    np.int64,\n",
    "    np.uint32,\n",
    "    np.uint64,\n",
    "    np.bool,\n",
    ")\n",
    "\n",
    "def as_array_py(arr, dtype=None):\n",
    "    \"\"\"Convert an object to a numerical NumPy array.\n",
    "    Avoid a copy if possible.\n",
    "    \"\"\"\n",
    "    if arr is None:\n",
    "        return None\n",
    "    if isinstance(arr, np.ndarray) and dtype is None:\n",
    "        return arr\n",
    "    if isinstance(arr, (int, float)):\n",
    "        arr = [arr]\n",
    "    out = np.asarray(arr)\n",
    "    if dtype is not None:\n",
    "        if out.dtype != dtype:\n",
    "            out = out.astype(dtype)\n",
    "    if out.dtype not in _ACCEPTED_ARRAY_DTYPES:\n",
    "        raise ValueError(\n",
    "            \"'arr' seems to have an invalid dtype: \" \"{0:s}\".format(str(out.dtype))\n",
    "        )\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.7 µs ± 6.41 ns per loop (mean ± std. dev. of 7 runs, 1000000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit as_array_py([1,2,3,4,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.11 µs ± 7.62 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit as_array_cy([1,2,3,4,5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ok, so it doesn't really speed it up but it's so fast anyway it doesn't matter!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That worked - onto `_index_of`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cython\n",
    "# cython: infer_types=True\n",
    "import numpy as np\n",
    "cimport numpy as npc\n",
    "cimport cython\n",
    "\n",
    "ctypedef fused my_type:\n",
    "    float\n",
    "    int\n",
    "    unsigned int\n",
    "    bint\n",
    "    list\n",
    "    npc.ndarray\n",
    "\n",
    "def index_of(my_type arr, my_type lookup):\n",
    "    \"\"\"Replace scalars in an array by their indices in a lookup table.\n",
    "    Implicitely assume that:\n",
    "    * All elements of arr and lookup are non-negative integers.\n",
    "    * All elements or arr belong to lookup.\n",
    "    This is not checked for performance reasons.\n",
    "    \"\"\"\n",
    "    # Equivalent of np.digitize(arr, lookup) - 1, but much faster.\n",
    "    # TODO: assertions to disable in production for performance reasons.\n",
    "    # TODO: np.searchsorted(lookup, arr) is faster on small arrays with large\n",
    "    # values\n",
    "    cdef npc.ndarray tmp\n",
    "    cdef int m\n",
    "    lookup_array = np.asarray(lookup, dtype=np.int32)\n",
    "    m = (lookup_array.max() if len(lookup_array) else 0) + 1\n",
    "    tmp = np.zeros(m + 1, dtype=np.int)\n",
    "    # Ensure that -1 values are kept.\n",
    "    tmp[-1] = -1\n",
    "    if len(lookup):\n",
    "        tmp[lookup] = np.arange(len(lookup))\n",
    "    return tmp[arr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_of([2], [1, 2, 3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now compare to pure python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def index_of_py(arr, lookup):\n",
    "    \"\"\"Replace scalars in an array by their indices in a lookup table.\n",
    "    Implicitely assume that:\n",
    "    * All elements of arr and lookup are non-negative integers.\n",
    "    * All elements or arr belong to lookup.\n",
    "    This is not checked for performance reasons.\n",
    "    \"\"\"\n",
    "    # Equivalent of np.digitize(arr, lookup) - 1, but much faster.\n",
    "    # TODO: assertions to disable in production for performance reasons.\n",
    "    # TODO: np.searchsorted(lookup, arr) is faster on small arrays with large\n",
    "    # values\n",
    "    lookup = np.asarray(lookup, dtype=np.int32)\n",
    "    m = (lookup.max() if len(lookup) else 0) + 1\n",
    "    tmp = np.zeros(m + 1, dtype=np.int)\n",
    "    # Ensure that -1 values are kept.\n",
    "    tmp[-1] = -1\n",
    "    if len(lookup):\n",
    "        tmp[lookup] = np.arange(len(lookup))\n",
    "    return tmp[arr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.66 µs ± 101 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit index_of_py([2], [1, 2, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11 µs ± 124 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit index_of([2], [1, 2, 3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, same thing for `index_of` - a bit slower with cython but again super fast so it probably doesn't matter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Onto `_unique`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cython\n",
    "# cython: infer_types=True\n",
    "import numpy as np\n",
    "cimport numpy as npc\n",
    "cimport cython\n",
    "\n",
    "# _ACCEPTED_ARRAY_DTYPES = (\n",
    "#     np.float,\n",
    "#     np.float32,\n",
    "#     np.float64,\n",
    "#     np.int,\n",
    "#     np.int8,\n",
    "#     np.int16,\n",
    "#     np.uint8,\n",
    "#     np.uint16,\n",
    "#     np.int32,\n",
    "#     np.int64,\n",
    "#     np.uint32,\n",
    "#     np.uint64,\n",
    "#     np.bool,\n",
    "# )\n",
    "\n",
    "ctypedef fused my_type:\n",
    "    float\n",
    "    int\n",
    "    unsigned int\n",
    "    bint\n",
    "    list\n",
    "    npc.ndarray\n",
    "    \n",
    "# NRK potential slowdown below with dtype unset.\n",
    "def _as_array(my_type arr):  #, dtype=None):\n",
    "    \"\"\"Convert an object to a numerical NumPy array.\n",
    "    Avoid a copy if possible.\n",
    "    \"\"\"\n",
    "    cdef list arr_temp = []\n",
    "#     if arr is None:\n",
    "#         return None\n",
    "    if isinstance(arr, np.ndarray): # and dtype is None:\n",
    "        return arr\n",
    "    if isinstance(arr, (int, float)):\n",
    "        \n",
    "        arr_temp = [arr]\n",
    "    out = np.asarray(arr_temp)\n",
    "#     if dtype is not None:\n",
    "#         if out.dtype != dtype:\n",
    "#             out = out.astype(dtype)\n",
    "#     if out.dtype not in _ACCEPTED_ARRAY_DTYPES:\n",
    "#         raise ValueError(\n",
    "#             \"'arr' seems to have an invalid dtype: \" \"{0:s}\".format(str(out.dtype))\n",
    "#         )\n",
    "    return out\n",
    "\n",
    "def unique(my_type x):\n",
    "    \"\"\"Faster version of np.unique().\n",
    "    This version is restricted to 1D arrays of non-negative integers.\n",
    "    It is only faster if len(x) >> len(unique(x)).\n",
    "    \"\"\"\n",
    "    cdef npc.ndarray bc\n",
    "    if x is None or len(x) == 0:\n",
    "        return np.array([], dtype=np.int64)\n",
    "    # WARNING: only keep positive values.\n",
    "    # cluster=-1 means \"unclustered\".\n",
    "    x_array = _as_array(x).astype('int')  # Adjust this back to _as_array when combining at end!\n",
    "    x_array = x_array[x_array >= 0]\n",
    "    bc = np.bincount(x_array)\n",
    "    return np.nonzero(bc)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 4, 5, 7, 9])"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique(np.asarray([1, 2, 2, 5, 4, 7, 9]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time the above versus np.unique out of interest!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now compare to pure python!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# Cross-correlograms\n",
    "# ------------------------------------------------------------------------------\n",
    "_ACCEPTED_ARRAY_DTYPES = (\n",
    "    np.float,\n",
    "    np.float32,\n",
    "    np.float64,\n",
    "    np.int,\n",
    "    np.int8,\n",
    "    np.int16,\n",
    "    np.uint8,\n",
    "    np.uint16,\n",
    "    np.int32,\n",
    "    np.int64,\n",
    "    np.uint32,\n",
    "    np.uint64,\n",
    "    np.bool,\n",
    ")\n",
    "\n",
    "def as_array_py(arr, dtype=None):\n",
    "    \"\"\"Convert an object to a numerical NumPy array.\n",
    "    Avoid a copy if possible.\n",
    "    \"\"\"\n",
    "    if arr is None:\n",
    "        return None\n",
    "    if isinstance(arr, np.ndarray) and dtype is None:\n",
    "        return arr\n",
    "    if isinstance(arr, (int, float)):\n",
    "        arr = [arr]\n",
    "    out = np.asarray(arr)\n",
    "    if dtype is not None:\n",
    "        if out.dtype != dtype:\n",
    "            out = out.astype(dtype)\n",
    "    if out.dtype not in _ACCEPTED_ARRAY_DTYPES:\n",
    "        raise ValueError(\n",
    "            \"'arr' seems to have an invalid dtype: \" \"{0:s}\".format(str(out.dtype))\n",
    "        )\n",
    "    return out\n",
    "\n",
    "def unique_py(x):\n",
    "    \"\"\"Faster version of np.unique().\n",
    "    This version is restricted to 1D arrays of non-negative integers.\n",
    "    It is only faster if len(x) >> len(unique(x)).\n",
    "    \"\"\"\n",
    "    if x is None or len(x) == 0:\n",
    "        return np.array([], dtype=np.int64)\n",
    "    # WARNING: only keep positive values.\n",
    "    # cluster=-1 means \"unclustered\".\n",
    "    x = as_array_py(x)\n",
    "    x = x[x >= 0]\n",
    "    bc = np.bincount(x)\n",
    "    return np.nonzero(bc)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.65 ms ± 6.77 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "rand_int = np.random.randint(0, 50, size=100000)\n",
    "\n",
    "%timeit np.unique(rand_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "399 µs ± 325 ns per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit unique(rand_int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, much faster than pure numpy (6x). Now compare to python implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "244 µs ± 189 ns per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit unique_py(rand_int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gah - somehow I'm slowing everything down with cython - maybe when we get to the final version it will be faster? Or maybe try the above with memoryviews?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, try to do `_unique` with memoryviews..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cython\n",
    "# cython: infer_types=True\n",
    "import numpy as np\n",
    "cimport numpy as npc\n",
    "cimport cython\n",
    "\n",
    "\n",
    "# _ACCEPTED_ARRAY_DTYPES = (\n",
    "#     np.float,\n",
    "#     np.float32,\n",
    "#     np.float64,\n",
    "#     np.int,\n",
    "#     np.int8,\n",
    "#     np.int16,\n",
    "#     np.uint8,\n",
    "#     np.uint16,\n",
    "#     np.int32,\n",
    "#     np.int64,\n",
    "#     np.uint32,\n",
    "#     np.uint64,\n",
    "#     np.bool,\n",
    "# )\n",
    "\n",
    "ctypedef fused my_type:\n",
    "    float\n",
    "    int\n",
    "    unsigned int\n",
    "    bint\n",
    "    list\n",
    "    npc.ndarray\n",
    "    \n",
    "# NRK potential slowdown below with dtype unset.\n",
    "@cython.boundscheck(False)  # Deactivate bounds checking\n",
    "@cython.wraparound(False)  # Deactivate negative indexing\n",
    "def _as_array_cym(my_type [:] arr):  #, dtype=None):\n",
    "    \"\"\"Convert an object to a numerical NumPy array.\n",
    "    Avoid a copy if possible.\n",
    "    \"\"\"\n",
    "    cdef list arr_temp = []\n",
    "#     if arr is None:\n",
    "#         return None\n",
    "    if isinstance(arr, np.ndarray): # and dtype is None:\n",
    "        return arr\n",
    "    if isinstance(arr, (int, float)):\n",
    "        \n",
    "        arr_temp = [arr]\n",
    "    out = np.asarray(arr_temp)\n",
    "#     if dtype is not None:\n",
    "#         if out.dtype != dtype:\n",
    "#             out = out.astype(dtype)\n",
    "#     if out.dtype not in _ACCEPTED_ARRAY_DTYPES:\n",
    "#         raise ValueError(\n",
    "#             \"'arr' seems to have an invalid dtype: \" \"{0:s}\".format(str(out.dtype))\n",
    "#         )\n",
    "    return out\n",
    "\n",
    "@cython.boundscheck(False)  # Deactivate bounds checking\n",
    "@cython.wraparound(False)  # Deactivate negative indexing\n",
    "def unique_cym(my_type [::1] x):\n",
    "    \"\"\"Faster version of np.unique().\n",
    "    This version is restricted to 1D arrays of non-negative integers.\n",
    "    It is only faster if len(x) >> len(unique(x)).\n",
    "    \"\"\"\n",
    "    cdef npc.ndarray [:] bc\n",
    "    if x is None or len(x) == 0:\n",
    "        return np.array([], dtype=np.int64)\n",
    "    # WARNING: only keep positive values.\n",
    "    # cluster=-1 means \"unclustered\".\n",
    "    x_array = _as_array_cym(x).astype('int')  # Adjust this back to _as_array when combining at end!\n",
    "    x_array = x_array[x_array >= 0]\n",
    "    bc = np.bincount(x_array)\n",
    "    return np.nonzero(bc)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "412 µs ± 1.67 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit unique_cym(rand_int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hmm, somehow adding in all the speed-up techniques from Cython actually slow this down a bunch!!! But again, it is still 6x faster than regular numpy..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Cross-correlograms.\"\"\"\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# Imports\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "# cython: infer_types=True\n",
    "import numpy as np\n",
    "cimport numpy as npc\n",
    "cimport cython\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# Cross-correlograms\n",
    "# ------------------------------------------------------------------------------\n",
    "_ACCEPTED_ARRAY_DTYPES = (\n",
    "    np.float,\n",
    "    np.float32,\n",
    "    np.float64,\n",
    "    np.int,\n",
    "    np.int8,\n",
    "    np.int16,\n",
    "    np.uint8,\n",
    "    np.uint16,\n",
    "    np.int32,\n",
    "    np.int64,\n",
    "    np.uint32,\n",
    "    np.uint64,\n",
    "    np.bool,\n",
    ")\n",
    "\n",
    "ctypedef fused my_type:\n",
    "    float\n",
    "    int\n",
    "    unsigned int\n",
    "    bint\n",
    "    list\n",
    "    npc.ndarray\n",
    "\n",
    "def _as_array(my_type arr, dtype=None):\n",
    "    \"\"\"Convert an object to a numerical NumPy array.\n",
    "    Avoid a copy if possible.\n",
    "    \"\"\"\n",
    "    cdef list arr_temp = []\n",
    "    if arr is None:\n",
    "        return None\n",
    "    if isinstance(arr, np.ndarray) and dtype is None:\n",
    "        return arr\n",
    "    if isinstance(arr, (int, float)):\n",
    "        arr_temp = [arr]\n",
    "    out = np.asarray(arr_temp)\n",
    "    if dtype is not None:\n",
    "        if out.dtype != dtype:\n",
    "            out = out.astype(dtype)\n",
    "    if out.dtype not in _ACCEPTED_ARRAY_DTYPES:\n",
    "        raise ValueError(\n",
    "            \"'arr' seems to have an invalid dtype: \" \"{0:s}\".format(str(out.dtype))\n",
    "        )\n",
    "    return out\n",
    "\n",
    "\n",
    "def _index_of(my_type arr, my_type lookup):\n",
    "    \"\"\"Replace scalars in an array by their indices in a lookup table.\n",
    "    Implicitely assume that:\n",
    "    * All elements of arr and lookup are non-negative integers.\n",
    "    * All elements or arr belong to lookup.\n",
    "    This is not checked for performance reasons.\n",
    "    \"\"\"\n",
    "    # Equivalent of np.digitize(arr, lookup) - 1, but much faster.\n",
    "    # TODO: assertions to disable in production for performance reasons.\n",
    "    # TODO: np.searchsorted(lookup, arr) is faster on small arrays with large\n",
    "    # values\n",
    "    cdef npc.ndarray tmp\n",
    "    cdef int m\n",
    "    lookup_array = np.asarray(lookup, dtype=np.int32)\n",
    "    m = (lookup_array.max() if len(lookup_array) else 0) + 1\n",
    "    tmp = np.zeros(m + 1, dtype=np.int)\n",
    "    # Ensure that -1 values are kept.\n",
    "    tmp[-1] = -1\n",
    "    if len(lookup):\n",
    "        tmp[lookup] = np.arange(len(lookup))\n",
    "    return tmp[arr]\n",
    "\n",
    "\n",
    "def _unique(my_type x):\n",
    "    \"\"\"Faster version of np.unique().\n",
    "    This version is restricted to 1D arrays of non-negative integers.\n",
    "    It is only faster if len(x) >> len(unique(x)).\n",
    "    \"\"\"\n",
    "    cdef npc.ndarray bc\n",
    "    if x is None or len(x) == 0:\n",
    "        return np.array([], dtype=np.int64)\n",
    "    # WARNING: only keep positive values.\n",
    "    # cluster=-1 means \"unclustered\".\n",
    "    x_array = _as_array(x).astype('int')  # Adjust this back to _as_array when combining at end!\n",
    "    x_array = x_array[x_array >= 0]\n",
    "    bc = np.bincount(x_array)\n",
    "    return np.nonzero(bc)[0]\n",
    "\n",
    "\n",
    "def _increment(my_type arr, my_type indices):\n",
    "    \"\"\"Increment some indices in a 1D vector of non-negative integers.\n",
    "    Repeated indices are taken into account.\"\"\"\n",
    "    arr_array = _as_array(arr)\n",
    "    indices_array = _as_array(indices)\n",
    "    bbins = np.bincount(indices_array)\n",
    "    arr_array[: len(bbins)] += bbins\n",
    "    return arr_array\n",
    "\n",
    "\n",
    "def _diff_shifted(my_type arr, int steps=1):\n",
    "    arr_array = _as_array(arr)\n",
    "    return arr_array[steps:] - arr_array[: len(arr) - steps]\n",
    "\n",
    "\n",
    "def _create_correlograms_array(int n_clusters, my_type winsize_bins):\n",
    "    return np.zeros((n_clusters, n_clusters, winsize_bins // 2 + 1), dtype=np.int32)\n",
    "\n",
    "\n",
    "def _symmetrize_correlograms(my_type correlograms):\n",
    "    \"\"\"Return the symmetrized version of the CCG arrays.\"\"\"\n",
    "\n",
    "    n_clusters, _, n_bins = correlograms.shape\n",
    "    assert n_clusters == _\n",
    "\n",
    "    # We symmetrize c[i, j, 0].\n",
    "    # This is necessary because the algorithm in correlograms()\n",
    "    # is sensitive to the order of identical spikes.\n",
    "    correlograms[..., 0] = np.maximum(correlograms[..., 0], correlograms[..., 0].T)\n",
    "\n",
    "    sym = correlograms[..., 1:][..., ::-1]\n",
    "    sym = np.transpose(sym, (1, 0, 2))\n",
    "\n",
    "    return np.dstack((sym, correlograms))\n",
    "\n",
    "\n",
    "def firing_rate(spike_clusters, cluster_ids=None, bin_size=None, duration=None):\n",
    "    \"\"\"Compute the average number of spikes per cluster per bin.\"\"\"\n",
    "\n",
    "    # Take the cluster order into account.\n",
    "    if cluster_ids is None:\n",
    "        cluster_ids = _unique(spike_clusters)\n",
    "    else:\n",
    "        cluster_ids = _as_array(cluster_ids)\n",
    "\n",
    "    # Like spike_clusters, but with 0..n_clusters-1 indices.\n",
    "    spike_clusters_i = _index_of(spike_clusters, cluster_ids)\n",
    "\n",
    "    assert bin_size > 0\n",
    "    bc = np.bincount(spike_clusters_i)\n",
    "    # Handle the case where the last cluster(s) are empty.\n",
    "    if len(bc) < len(cluster_ids):\n",
    "        n = len(cluster_ids) - len(bc)\n",
    "        bc = np.concatenate((bc, np.zeros(n, dtype=bc.dtype)))\n",
    "    assert bc.shape == (len(cluster_ids),)\n",
    "    return bc * np.c_[bc] * (bin_size / (duration or 1.0))\n",
    "\n",
    "\n",
    "def correlograms(\n",
    "    my_type spike_times,\n",
    "    my_type spike_clusters,\n",
    "    cluster_ids=None,\n",
    "    my_type sample_rate=30000,\n",
    "    bin_size=None,\n",
    "    window_size=None,\n",
    "    bint symmetrize=True,\n",
    "):\n",
    "    \"\"\"Compute all pairwise cross-correlograms among the clusters appearing\n",
    "    in `spike_clusters`.\n",
    "    Parameters\n",
    "    ----------\n",
    "    spike_times : array-like\n",
    "        Spike times in seconds.\n",
    "    spike_clusters : array-like\n",
    "        Spike-cluster mapping.\n",
    "    cluster_ids : array-like\n",
    "        The list of *all* unique clusters, in any order. That order will be used\n",
    "        in the output array.\n",
    "    bin_size : float\n",
    "        Size of the bin, in seconds.\n",
    "    window_size : float\n",
    "        Size of the window, in seconds.\n",
    "    sample_rate : float\n",
    "        Sampling rate.\n",
    "    symmetrize : boolean (True)\n",
    "        Whether the output matrix should be symmetrized or not.\n",
    "    Returns\n",
    "    -------\n",
    "    correlograms : array\n",
    "        A `(n_clusters, n_clusters, winsize_samples)` array with all pairwise CCGs.\n",
    "    \"\"\"\n",
    "    assert sample_rate > 0.0\n",
    "    assert np.all(np.diff(spike_times) >= 0), \"The spike times must be \" \"increasing.\"\n",
    "\n",
    "    # Get the spike samples.\n",
    "    spike_times = np.asarray(spike_times, dtype=np.float64)\n",
    "    spike_samples = (spike_times * sample_rate).astype(np.int64)\n",
    "\n",
    "    spike_clusters_array = _as_array(spike_clusters)\n",
    "\n",
    "    assert spike_samples.ndim == 1\n",
    "    assert spike_samples.shape == spike_clusters_array.shape\n",
    "\n",
    "    # Find `binsize`.\n",
    "    bin_size2 = np.clip(bin_size, 1e-5, 1e5)  # in seconds\n",
    "    binsize = int(sample_rate * bin_size2)  # in samples\n",
    "    assert binsize >= 1\n",
    "\n",
    "    # Find `winsize_bins`.\n",
    "    window_size2 = np.clip(window_size, 1e-5, 1e5)  # in seconds\n",
    "    winsize_bins = 2 * int(0.5 * window_size2 / bin_size) + 1\n",
    "\n",
    "    assert winsize_bins >= 1\n",
    "    assert winsize_bins % 2 == 1\n",
    "\n",
    "    # Take the cluster order into account.\n",
    "    if cluster_ids is None:\n",
    "        clusters_use = _unique(spike_clusters_array)\n",
    "    else:\n",
    "        clusters_use = _as_array(cluster_ids)\n",
    "    n_clusters = len(clusters_use)\n",
    "\n",
    "    # Like spike_clusters, but with 0..n_clusters-1 indices.\n",
    "    spike_clusters_i = _index_of(spike_clusters_array, clusters_use)\n",
    "\n",
    "    # Shift between the two copies of the spike trains.\n",
    "    cdef int shift = 1\n",
    "\n",
    "    # At a given shift, the mask precises which spikes have matching spikes\n",
    "    # within the correlogram time window.\n",
    "    mask = np.ones_like(spike_samples, dtype=np.bool)\n",
    "\n",
    "    correlograms = _create_correlograms_array(n_clusters, winsize_bins)\n",
    "\n",
    "    # The loop continues as long as there is at least one spike with\n",
    "    # a matching spike.\n",
    "    while mask[:-shift].any():\n",
    "        # Number of time samples between spike i and spike i+shift.\n",
    "        spike_diff = _diff_shifted(spike_samples, shift)\n",
    "\n",
    "        # Binarize the delays between spike i and spike i+shift.\n",
    "        spike_diff_b = spike_diff // binsize\n",
    "\n",
    "        # Spikes with no matching spikes are masked.\n",
    "        mask[:-shift][spike_diff_b > (winsize_bins // 2)] = False\n",
    "\n",
    "        # Cache the masked spike delays.\n",
    "        m = mask[:-shift].copy()\n",
    "        d = spike_diff_b[m]\n",
    "\n",
    "        # # Update the masks given the clusters to update.\n",
    "        # m0 = np.in1d(spike_clusters[:-shift], clusters)\n",
    "        # m = m & m0\n",
    "        # d = spike_diff_b[m]\n",
    "        d = spike_diff_b[m]\n",
    "\n",
    "        # Find the indices in the raveled correlograms array that need\n",
    "        # to be incremented, taking into account the spike clusters.\n",
    "        indices = np.ravel_multi_index(\n",
    "            (spike_clusters_i[:-shift][m], spike_clusters_i[+shift:][m], d),\n",
    "            correlograms.shape,\n",
    "        )\n",
    "\n",
    "        # Increment the matching spikes in the correlograms array.\n",
    "        _increment(correlograms.ravel(), indices)\n",
    "\n",
    "        shift += 1\n",
    "\n",
    "    if symmetrize:\n",
    "        return _symmetrize_correlograms(correlograms)\n",
    "    else:\n",
    "        return correlograms\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:opto2] *",
   "language": "python",
   "name": "conda-env-opto2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
